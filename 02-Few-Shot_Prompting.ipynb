{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 1. Tổng quan\n",
    "\n",
    "```Few-shot prompting``` là một kỹ thuật trong lĩnh vực xử lý ngôn ngữ tự nhiên (NLP) sử dụng các mô hình ngôn ngữ lớn (LLMs), trong đó người dùng cung cấp một số ví dụ minh họa (thường từ 2 đến 5) về nhiệm vụ cần thực hiện trực tiếp trong prompt. Các ví dụ này đóng vai trò hướng dẫn mô hình nhận diện mẫu (pattern) và áp dụng quy tắc đó cho dữ liệu mới, mà không cần huấn luyện lại mô hình hay cập nhật tham số nội bộ. Few-shot prompting nằm giữa zero-shot (không có ví dụ) và fine-tuning (huấn luyện lại với tập dữ liệu lớn), tận dụng khả năng học trong ngữ cảnh (in-context learning) của LLMs để thích ứng nhanh với các tác vụ mới\n",
    "\n",
    "# 2. Đặc điểm\n",
    "* Cung cấp ví dụ minh họa: Prompt chứa một số cặp input–output tiêu biểu, giúp mô hình hiểu rõ yêu cầu và định dạng mong muốn.\n",
    "* Học trong ngữ cảnh (in-context learning): Mô hình không thay đổi tham số, mà dựa vào các ví dụ để nhận diện mẫu và tổng quát hóa cho trường hợp mới.\n",
    "* Tăng độ chính xác: So với zero-shot, few-shot giúp mô hình thực hiện tốt hơn các tác vụ phức tạp hoặc có cấu trúc đầu ra đặc thù.\n",
    "* Linh hoạt và tiết kiệm chi phí: Không cần tập dữ liệu lớn hay huấn luyện lại, dễ dàng điều chỉnh cho nhiều tác vụ khác nhau chỉ bằng cách thay đổi ví dụ trong prompt.\n",
    "* Hiệu quả phụ thuộc vào chất lượng ví dụ: Kết quả đầu ra chịu ảnh hưởng mạnh bởi tính đa dạng, rõ ràng và liên quan của các ví dụ được chọn.\n",
    "* Giới hạn số lượng ví dụ: Thường chỉ cần 2–5 ví dụ; quá nhiều có thể gây quá khớp (overfitting) hoặc làm prompt quá dài, ảnh hưởng hiệu suất\n",
    "\n",
    "# 3. Best Practices\n",
    "Để tối ưu hiệu quả few-shot prompting, các nguyên tắc thực hành tốt bao gồm:\n",
    "* Chọn ví dụ đa dạng và đại diện: Đảm bảo các ví dụ bao quát nhiều trường hợp và khía cạnh khác nhau của tác vụ, giúp mô hình tổng quát hóa tốt hơn.\n",
    "* Giữ định dạng nhất quán: Các ví dụ nên có cấu trúc giống nhau về cách trình bày input và output, giúp mô hình dễ nhận diện mẫu.\n",
    "* Sử dụng cả ví dụ tích cực và tiêu cực: Nếu phù hợp, cung cấp cả ví dụ đúng và sai để mô hình hiểu rõ phạm vi đầu ra mong muốn.\n",
    "* Sắp xếp ví dụ ngẫu nhiên: Tránh để mô hình học máy móc theo thứ tự, tăng khả năng tổng quát hóa.\n",
    "* Không dùng quá nhiều ví dụ: Thường chỉ cần 2–5 ví dụ; quá nhiều có thể gây nhiễu hoặc vượt quá giới hạn token của mô hình.\n",
    "* Kiểm tra và tinh chỉnh: Thử nghiệm nhiều tổ hợp ví dụ và cấu trúc prompt để tìm ra thiết lập hiệu quả nhất cho từng tác vụ cụ thể.\n",
    "\n",
    "# 4.Ví dụ"
   ],
   "id": "854ead2bbe03a2ff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T01:30:57.912707Z",
     "start_time": "2025-04-28T01:30:57.657075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ],
   "id": "ab72896be6adde4e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T01:30:59.686285Z",
     "start_time": "2025-04-28T01:30:57.913824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = init_chat_model(\n",
    "    model='gpt-4o-mini', \n",
    "    model_provider='openai',\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "\n",
    "messages = [\n",
    "    # Instruction\n",
    "    SystemMessage('Trong vai trò chuyên gia vật lý, hãy giúp tôi đổi độ C ra độ F, cho kết quả mà không cần giải thích quá nhiều'),\n",
    "    \n",
    "    # Examples\n",
    "    HumanMessage('Đổi 0 độ C ra độ F'),\n",
    "    AIMessage('32 Fahrenheit'),\n",
    "    HumanMessage('Đổi 100 độ C ra độ F'),\n",
    "    AIMessage('212 Fahrenheit'),\n",
    "    \n",
    "    # User query\n",
    "    HumanMessage('Đổi 37 độ C ra độ F'),\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "print(response.content)  # Kết quả đúng: 98.6 Fahrenheit"
   ],
   "id": "fc1654603ae96721",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.6 Fahrenheit\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T01:30:59.689928Z",
     "start_time": "2025-04-28T01:30:59.687656Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "8a18626371bbea39",
   "outputs": [],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
